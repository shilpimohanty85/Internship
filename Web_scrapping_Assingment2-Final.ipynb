{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bb29820",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4457d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing selenium\n",
    "#!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b236e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d11e7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91845\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15406fda",
   "metadata": {},
   "source": [
    "# QUESTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc3947",
   "metadata": {},
   "source": [
    "1.we will scrape data from https://www.naukri.com/website for Data Analyst position for Bnagalore location.We will scrape 4 firlds for each job as mentioned below:\n",
    " 1)Job title 2)Job location 3)company_name 4)Experience required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a79432e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the naukri portal url on the web driver\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "78d2151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for finding Data Analyst on search job bar using id\n",
    "search_job=driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3a3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for finading Bangalore on search locn bar using absolute xpath\n",
    "search_locn =driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_locn.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15d9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for clicking button using absolute xpath function\n",
    "search_btn=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c9933b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring Data analyst with Pharma Background acr...</td>\n",
       "      <td>HCL</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Coordinator | Data Analyst | MS Excel | T...</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>software developer &amp; Testing / Business Analys...</td>\n",
       "      <td>SECRET TECHNOLOGIES INDIA VMS GROUP</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "      <td>Pune, Bangalore/Bengaluru(Shivaji Nagar), Mumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Business Data Analyst - FDP</td>\n",
       "      <td>Intuit Inc.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - IIM/ISB/MDI/FMS/SP Jain</td>\n",
       "      <td>K12 Techno Services Pvt Ltd</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Capco</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Mobile Premier League</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Analyst!!!</td>\n",
       "      <td>Ignitho</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SunEdison</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0  Hiring Data analyst with Pharma Background acr...   \n",
       "1  Data Coordinator | Data Analyst | MS Excel | T...   \n",
       "2  software developer & Testing / Business Analys...   \n",
       "3                  Staff Business Data Analyst - FDP   \n",
       "4             Data Analyst - IIM/ISB/MDI/FMS/SP Jain   \n",
       "5                                Senior Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                         Hiring For Data Analyst!!!   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                      Company Experience  \\\n",
       "0                                         HCL   6-11 Yrs   \n",
       "1  Inspiration Manpower Consultancy Pvt. Ltd.    0-4 Yrs   \n",
       "2         SECRET TECHNOLOGIES INDIA VMS GROUP    5-7 Yrs   \n",
       "3                                 Intuit Inc.    4-9 Yrs   \n",
       "4                 K12 Techno Services Pvt Ltd    4-8 Yrs   \n",
       "5                                       Capco    3-6 Yrs   \n",
       "6                       Mobile Premier League    3-6 Yrs   \n",
       "7                                    Flipkart    3-8 Yrs   \n",
       "8                                     Ignitho    2-7 Yrs   \n",
       "9                                   SunEdison    0-2 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  \n",
       "1               Bangalore/Bengaluru(Sadashiva Nagar)  \n",
       "2  Pune, Bangalore/Bengaluru(Shivaji Nagar), Mumb...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8   Chennai, Bangalore/Bengaluru\\n(WFH during Covid)  \n",
       "9            Bangalore/Bengaluru, Mumbai (All Areas)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the job titles\n",
    "title_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles=[]\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "# extract all the location\n",
    "locn_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "Location=[]\n",
    "for i in locn_tags[:10]:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "#extracting all company names\n",
    "company_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')  \n",
    "company_names=[]\n",
    "\n",
    "for i in company_tags[:10]:\n",
    "    company_names.append(i.text)\n",
    "    \n",
    "#extarcting all the experience    \n",
    "exp_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "experience=[]\n",
    "for i in exp_tags[:10]:\n",
    "    experience.append(i.text) \n",
    "    \n",
    "#checking the length     \n",
    "len(job_titles),len(company_names),len(experience),len(Location)    \n",
    "\n",
    "# creating the dataframe now\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Titles']=job_titles\n",
    "jobs['Company']=company_names\n",
    "jobs['Experience']=experience\n",
    "jobs['Location']=Location\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2cd87",
   "metadata": {},
   "source": [
    "# QUESTION :2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a02514",
   "metadata": {},
   "source": [
    "   To scrape data for “Data Scientist” Job position in “Bangalore” locationfrom https://www.naukri.com/website. \n",
    "   We will scrape 3 fields for each job as mentioned : 1)Job title 2)Job location 3)company_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1e6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20704923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching Data Scientist on search bar\n",
    "search_job=driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c59a57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting location on search bar using absolute xpath\n",
    "search_locn =driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_locn.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602c9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for click button using absolute xpath function\n",
    "search_btn=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b418d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>HDFC Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior/ Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AmoliTalents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>open data fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Concentrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Scientist - Analytics</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Firstsource Solutions Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Computer Vision Python Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>OceanOfWeb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent Opportunity For Freshers For AI/ML, ...</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>NTT Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Titan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                        Senior/ Lead Data Scientist   \n",
       "3                           Data Scientist / Analyst   \n",
       "4    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "5                  Hiring Data Scientist - Analytics   \n",
       "6              Computer Vision Python Data Scientist   \n",
       "7  Excellent Opportunity For Freshers For AI/ML, ...   \n",
       "8                              Junior Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "5            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "6  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "7  Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                         Company  \n",
       "0                      HDFC Bank  \n",
       "1                          Shell  \n",
       "2                   AmoliTalents  \n",
       "3               open data fabric  \n",
       "4                     Concentrix  \n",
       "5  Firstsource Solutions Limited  \n",
       "6                     OceanOfWeb  \n",
       "7                       NTT Data  \n",
       "8                          Titan  \n",
       "9                         Amazon  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all job titles\n",
    "title_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles=[]\n",
    "\n",
    "for i in title_tags:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "#extract all company names\n",
    "company_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')  \n",
    "company_names=[]\n",
    "for i in company_tags:\n",
    "    company_names.append(i.text)\n",
    "\n",
    "\n",
    "#extract all job location\n",
    "locn_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "Location=[]\n",
    "for i in locn_tags:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "#checking the length\n",
    "len(job_titles),len(company_names),len(Location)\n",
    "\n",
    "#creating dataframe\n",
    "jobs1=pd.DataFrame()\n",
    "jobs1['Job Titles']=job_titles\n",
    "jobs1['Location']=Location\n",
    "jobs1['Company']=company_names\n",
    "jobs1[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc40cd",
   "metadata": {},
   "source": [
    "# QUESTION :3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc9f37",
   "metadata": {},
   "source": [
    " 3.To scrape data for “Data Scientist” Job position from https://www.naukri.com/website by\n",
    "   using location and salary filter.\n",
    "   The location filter used is “Delhi/NCR”. The salary filter used is “3-6” lakhs \n",
    "   We will scrape 4 fields for each job as mentioned :\n",
    "   1)Job title 2)Job location 3)company_name 4)Experience required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc863b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0758ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##code for finding Data Scientist on search job bar using id \n",
    "search_job=driver.find_element_by_class_name(\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07b65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for clicking button using absolute xpath function\n",
    "search_btn=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b6263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Location filter as 'DELHI/NCR'\n",
    "Location_check=driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "Location_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f1bb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the salary filter for \"3-6 Lakhs\"\n",
    "salary_check=driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac793a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent Opportunity For Freshers For AI/ML, ...</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>NTT Data</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Data Scientist / Business Analy...</td>\n",
       "      <td>Noida, New Delhi, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist _NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Analyst/ Scientist- Fresher Position</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Sejal Consulting Hub</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Only Fresher / Python Data Scientist / Trainee...</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Delhi / NCR\\n(WFH during Covid)</td>\n",
       "      <td>Indihire HR Consultants Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>Noida, Delhi / NCR</td>\n",
       "      <td>HCL</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Titles  \\\n",
       "0  Excellent Opportunity For Freshers For AI/ML, ...   \n",
       "1  Data Analyst / Data Scientist / Business Analy...   \n",
       "2                                Data Scientist _NLP   \n",
       "3   Junior Data Analyst/ Scientist- Fresher Position   \n",
       "4                     Data Scientist - MIND Infotech   \n",
       "5                     Data Scientist - MIND Infotech   \n",
       "6  Only Fresher / Python Data Scientist / Trainee...   \n",
       "7                                Lead Data Scientist   \n",
       "8      Urgent Requirement || Data Scientist || Noida   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...   \n",
       "1                      Noida, New Delhi, Delhi / NCR   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...   \n",
       "3  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "4                                              Noida   \n",
       "5                                              Noida   \n",
       "6                 Noida, New Delhi, Gurgaon/Gurugram   \n",
       "7                    Delhi / NCR\\n(WFH during Covid)   \n",
       "8                                 Noida, Delhi / NCR   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                                    Company Experience  \n",
       "0                                  NTT Data    0-0 Yrs  \n",
       "1                 GABA Consultancy services    0-0 Yrs  \n",
       "2                                       EXL    3-8 Yrs  \n",
       "3                      Sejal Consulting Hub    0-3 Yrs  \n",
       "4  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs  \n",
       "5  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED    4-8 Yrs  \n",
       "6                 GABA Consultancy services    0-0 Yrs  \n",
       "7   Indihire HR Consultants Private Limited    2-4 Yrs  \n",
       "8                                       HCL    3-8 Yrs  \n",
       "9                   Boston Consulting Group    2-5 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the job titles\n",
    "title_tags=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "job_titles=[]\n",
    "\n",
    "for i in title_tags[:10]:\n",
    "    job_titles.append(i.text)\n",
    "    \n",
    "# extract all the location\n",
    "locn_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "Location=[]\n",
    "  \n",
    "for i in locn_tags[:10]:\n",
    "    Location.append(i.text)\n",
    "    \n",
    "# extract all the company names\n",
    "company_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]') \n",
    "company_names=[]\n",
    "\n",
    "for i in company_tags[:10]:\n",
    "    company_names.append(i.text)\n",
    "    \n",
    "#extracting all the experience\n",
    "exp_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')  \n",
    "experience=[]\n",
    "\n",
    "for i in exp_tags[:10]:\n",
    "    experience.append(i.text)\n",
    "\n",
    "#checking length\n",
    "len(job_titles),len(company_names),len(experience),len(Location)\n",
    "\n",
    "jobs=pd.DataFrame()\n",
    "jobs['Job Titles']=job_titles\n",
    "jobs['Location']=Location\n",
    "jobs['Company']=company_names\n",
    "jobs['Experience']=experience\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9343e",
   "metadata": {},
   "source": [
    "# QUESTION 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfdc12a",
   "metadata": {},
   "source": [
    "4.We have to scrape data of first 100 sunglasses listings on flipkart.com.\n",
    "We have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d1f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the flipkart shopping site url on the web driver\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfde6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to write sunglasses in the search box\n",
    "search_prod=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_prod.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b775e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for clicking search button using absolute xpath function\n",
    "search_btn=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2cc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists\n",
    "brand=[]\n",
    "prod_desc=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#As we need to scrap for 100 products so we will take a for loop which will iterate 3 times since we need to collect data from 3 pages\n",
    " \n",
    "for i in range(0,4):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        prod_desc.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(j.text)\n",
    "      \n",
    "    #Path for next page inside same loop and appending numbers as pages change  \n",
    "    k=i+1\n",
    "    next_page=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=\"+str(k)\n",
    "    driver.get(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f664fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 160 160 160\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of the data scraped\n",
    "print(len(brand),len(prod_desc),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171fc46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Description</th>\n",
       "      <th>Sunglasses Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹234</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹234</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (59)</td>\n",
       "      <td>₹929</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹317</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹170</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹175</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Night Vision, UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹149</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Wayfarer Su...</td>\n",
       "      <td>₹203</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (17)</td>\n",
       "      <td>₹859</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (59)</td>\n",
       "      <td>₹749</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Product                                        Description  \\\n",
       "0          GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "1          SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...   \n",
       "2            IDEE          UV Protection Rectangular Sunglasses (59)   \n",
       "3    Silver Kartz           UV Protection Clubmaster Sunglasses (53)   \n",
       "4            SRPM             UV Protection Wayfarer Sunglasses (53)   \n",
       "..            ...                                                ...   \n",
       "95         PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "96           SRPM  Night Vision, UV Protection Round Sunglasses (54)   \n",
       "97         SUNBEE  UV Protection, Polarized, Mirrored Wayfarer Su...   \n",
       "98           IDEE              UV Protection Cat-eye Sunglasses (17)   \n",
       "99  VINCENT CHASE             UV Protection Wayfarer Sunglasses (59)   \n",
       "\n",
       "   Sunglasses Price Discount  \n",
       "0              ₹234  88% off  \n",
       "1              ₹234  86% off  \n",
       "2              ₹929  62% off  \n",
       "3              ₹317  78% off  \n",
       "4              ₹170  82% off  \n",
       "..              ...      ...  \n",
       "95             ₹175  89% off  \n",
       "96             ₹149  85% off  \n",
       "97             ₹203  84% off  \n",
       "98             ₹859  61% off  \n",
       "99             ₹749  62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame now\n",
    "df = pd.DataFrame()\n",
    "df['Product']=brand[:100]\n",
    "df['Description']=prod_desc[:100]\n",
    "df['Sunglasses Price']=price[:100]\n",
    "df['Discount']=discount[:100]\n",
    "df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e012de",
   "metadata": {},
   "source": [
    "# QUESTION-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07a0219",
   "metadata": {},
   "source": [
    "we are required to scrape first 100 reviews including three attributes as below:\n",
    "1.Rating\n",
    "2.Review summary\n",
    "3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53568ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1775884",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a')\n",
    "\n",
    "# extract all the job search links from the above search result\n",
    "prod_urls=[]\n",
    "for i in url[:11]:\n",
    "    prod_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7fe1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty lists\n",
    "rating=[]\n",
    "summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#As there are 10 reviews per page so we will ierate for 10 times for the required data\n",
    "\n",
    "for i in range(0,11):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        rating.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        summary.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        full_review.append(j.text)\n",
    "        \n",
    "    #Path for next page as it changes for every page \n",
    "    driver.find_element_by_xpath('/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[1]').click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be04036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110 110\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of the data scraped\n",
    "print(len(rating),len(summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86344e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating               Review  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5   Highly recommended   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                         Full summary  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  i11 is worthy to buy, too much happy with the ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe\n",
    "df=pd.DataFrame()\n",
    "df['Rating']=rating[:100]\n",
    "df['Review']=summary[:100]\n",
    "df['Full summary']=full_review[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7517b6",
   "metadata": {},
   "source": [
    "# QUESTION:6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36a2fa",
   "metadata": {},
   "source": [
    " Scraping data for first 100 sneakers from flipkart.com The follwing attributes of each sneaker has to be scrapped:\n",
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "4.Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c184542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee843d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching sneakers in the search bar and clicking the search button\n",
    "search_bar=driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "driver.find_element_by_xpath(\"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96165127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "brand=[]\n",
    "prod_desc=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#Scraping for 100 products and considerering the data from first 3 pages while iterating for 3 times  \n",
    "for i in range(0,5):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        prod_desc.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3I9_wc']\"):\n",
    "        price.append(j.text)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\"):\n",
    "        discount.append(j.text)\n",
    "        \n",
    "   #Path for next page as it changes for every page \n",
    "    driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[1]').click()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4ad95cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 200 165 200 200\n"
     ]
    }
   ],
   "source": [
    "# checking the length \n",
    "print(\"Lengths of columns:\", len(brand), len(prod_desc), len(price), len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b9ac036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹1,598</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corsac</td>\n",
       "      <td>5011-Latest Collection Stylish Casual Loafer S...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHELBY</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹1,299</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Varito</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,199</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Men's Sneakers Fashion Lightweight Running Sho...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹3,499</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>41% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                        Description  \\\n",
       "0                Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "1              Magnolia                                   Sneakers For Men   \n",
       "2                corsac  5011-Latest Collection Stylish Casual Loafer S...   \n",
       "3                SHELBY      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4   World Wear Footwear  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "..                  ...                                                ...   \n",
       "95               Varito                                   Sneakers For Men   \n",
       "96            DUNKASTON  Men's Sneakers Fashion Lightweight Running Sho...   \n",
       "97                 aadi  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "98               BRUTON                                   Sneakers For Men   \n",
       "99             RapidBox  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "\n",
       "     Price  Discount  \n",
       "0   ₹1,598   68% off  \n",
       "1     ₹999   67% off  \n",
       "2   ₹1,499   71% off  \n",
       "3   ₹1,299   61% off  \n",
       "4     ₹499   70% off  \n",
       "..     ...       ...  \n",
       "95  ₹2,199   79% off  \n",
       "96  ₹1,499   82% off  \n",
       "97    ₹999   73% off  \n",
       "98  ₹3,499   87% off  \n",
       "99    ₹999   41% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame now\n",
    "df = pd.DataFrame()\n",
    "df[' Brand']=brand[:100]\n",
    "df[' Description']=prod_desc[:100]\n",
    "df[' Price']=price[:100]\n",
    "df[' Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7500f",
   "metadata": {},
   "source": [
    "# QUESTION:7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fec2e",
   "metadata": {},
   "source": [
    "Scrapping first 100 shoes data having filter as Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”.\n",
    "Attributes to be scrapped are  “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c25b4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the myntra site for shoe scrapping url on the web driver\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbea1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have to click two price filters for the required range first price filter \"Rs. 7134 to Rs. 14089\" \n",
    "price_filter1 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "122aeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second price filter from Rs 14089 to Rs.21044\n",
    "price_filter2 = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[3]/label/div')\n",
    "price_filter2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d67aea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the color filter for \"Black\"\n",
    "color_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3f215c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the empty lists\n",
    "brand=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "\n",
    "#We can see that there are 50 products in one page, and as we need to scrap for 100 products, we need to take 2 pages data\n",
    "for i in range(0,2):\n",
    "    #Finding the tags having the brand name\n",
    "    for j in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        brand.append(j.text) \n",
    "    \n",
    "    #Finding the tags having short description of the shoe\n",
    "    for j in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        short_desc.append(j.text) \n",
    "        \n",
    "    #Finding the tags having the price of the shoe\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='product-price']\"):\n",
    "        price.append(j.text)  \n",
    "        \n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40fe2788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 100 100 100\n"
     ]
    }
   ],
   "source": [
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(brand), len(short_desc), len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "090e0d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Shoe Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 15999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Winflo 7 Running Shoes</td>\n",
       "      <td>Rs. 7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Printed Sneakers</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Electrify Nitro Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather High-Top Block Heeled Boots</td>\n",
       "      <td>Rs. 14025Rs. 16500(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Kitten Heeled Boots</td>\n",
       "      <td>Rs. 8415Rs. 9900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Printed Flatform Heeled Boots with Buckles</td>\n",
       "      <td>Rs. 8415Rs. 9900(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Shoe Brand                            Shoe Description  \\\n",
       "0        ALDO                         Men Leather Loafers   \n",
       "1        Nike                  Men Winflo 7 Running Shoes   \n",
       "2        ALDO                        Men Printed Sneakers   \n",
       "3        ALDO                   Men Leather Driving Shoes   \n",
       "4        Puma               Electrify Nitro Running Shoes   \n",
       "..        ...                                         ...   \n",
       "95    Saint G         Leather High-Top Block Heeled Boots   \n",
       "96    Saint G                 Leather Kitten Heeled Boots   \n",
       "97   DAVINCHI             Men Solid Leather Formal Derbys   \n",
       "98    Saint G  Printed Flatform Heeled Boots with Buckles   \n",
       "99   DAVINCHI         Men Textured Formal Leather Loafers   \n",
       "\n",
       "                     Shoe Price  \n",
       "0                     Rs. 15999  \n",
       "1                      Rs. 7995  \n",
       "2    Rs. 9099Rs. 12999(30% OFF)  \n",
       "3                     Rs. 12999  \n",
       "4                      Rs. 9999  \n",
       "..                          ...  \n",
       "95  Rs. 14025Rs. 16500(15% OFF)  \n",
       "96    Rs. 8415Rs. 9900(15% OFF)  \n",
       "97                     Rs. 9990  \n",
       "98    Rs. 8415Rs. 9900(15% OFF)  \n",
       "99                     Rs. 8990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame now\n",
    "df = pd.DataFrame()\n",
    "df['Shoe Brand']=brand[:100]\n",
    "df['Shoe Description']=short_desc[:100]\n",
    "df['Shoe Price']=price[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a69714",
   "metadata": {},
   "source": [
    "# QUESTION :8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67978c",
   "metadata": {},
   "source": [
    "Scraping first 10 laptops data using set filter as set CPU Type filter to “Intel Core i7” and “Intel Core i9” \n",
    "Scraping following attributes as :\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28476fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the amazon shopping site url on the web driver\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1df7ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write laptop in the search box\n",
    "search_prod = driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]')\n",
    "search_prod.send_keys(\"Laptop\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to click on the CPU filter for \"Intel Core i7\"\n",
    "filter1 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[5]/li[11]/span/a/div/label/i')\n",
    "filter1.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "635dbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the CPU filter for \"Intel Core i9\"\n",
    "filter2 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[14]/span/a/div/label/i')\n",
    "filter2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ec0f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Rating</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP 14s 11th Gen Intel Core i3- 8GB RAM/256GB S...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion 14,11th Gen Intel Core i5 16GB RAM...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>67,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>1,43,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1,48,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>1,54,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>2,32,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) HP Omen 15-dh0139TX Gaming Laptop (9...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>1,38,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Redmi Book Pro Intel Core i5 11th Gen 15.6-inc...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>47,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RedmiBook 15 e-Learning Edition Core i3 11th G...</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "      <td>37,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP ZBook Power G8/ Intel Core i9-11950H 2.5GHz...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>2,93,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title       Laptop Rating  \\\n",
       "0  HP 14s 11th Gen Intel Core i3- 8GB RAM/256GB S...  4.2 out of 5 stars   \n",
       "1  HP Pavilion 14,11th Gen Intel Core i5 16GB RAM...  4.4 out of 5 stars   \n",
       "2  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...  4.3 out of 5 stars   \n",
       "3  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...  5.0 out of 5 stars   \n",
       "4  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  4.3 out of 5 stars   \n",
       "5  HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...  1.0 out of 5 stars   \n",
       "6  (Renewed) HP Omen 15-dh0139TX Gaming Laptop (9...  4.3 out of 5 stars   \n",
       "7  Redmi Book Pro Intel Core i5 11th Gen 15.6-inc...  4.1 out of 5 stars   \n",
       "8  RedmiBook 15 e-Learning Edition Core i3 11th G...  3.4 out of 5 stars   \n",
       "9  HP ZBook Power G8/ Intel Core i9-11950H 2.5GHz...  4.3 out of 5 stars   \n",
       "\n",
       "  Laptop Price  \n",
       "0       39,990  \n",
       "1       67,490  \n",
       "2     1,43,990  \n",
       "3     1,48,990  \n",
       "4     1,54,890  \n",
       "5     2,32,000  \n",
       "6     1,38,000  \n",
       "7       47,990  \n",
       "8       37,990  \n",
       "9     2,93,000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract laptop title\n",
    "laptitle=[]\n",
    "lap_title = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in lap_title[:10]:\n",
    "    laptitle.append(i.text)\n",
    "\n",
    "# code to extract laptop rating\n",
    "laprating=[]\n",
    "lap_rating = driver.find_elements_by_class_name(\"a-icon-alt\")\n",
    "for i in lap_rating[:10]:\n",
    "    laprating.append(i.get_attribute('textContent'))\n",
    "\n",
    "# code to extract laptop price\n",
    "lapprice=[]\n",
    "lap_price = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in lap_price[:10]:\n",
    "    lapprice.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(laptitle), len(laprating), len(lapprice))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame()\n",
    "df['Laptop Title']=laptitle\n",
    "df['Laptop Rating']=laprating\n",
    "df['Laptop Price']=lapprice\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd3f1d",
   "metadata": {},
   "source": [
    "# QUESTION:9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e91eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scraping data for first 10 job results for Data Scientist Designation in Noida.Scrapping following attributes:\n",
    "1.company name\n",
    "2.No. of days ago when job was posted\n",
    "3.Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e793d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the ambitionbox url on the web driver\n",
    "url='https://www.ambitionbox.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc1dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click job box  on the search button\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62eb0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Data Scientist on search bar \n",
    "search_locn =driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input')\n",
    "search_locn.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "650a2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for clicking search button using absolute xpath function\n",
    "search_btn=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div/div/div/button')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51bf6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the location button to find Noida on search\n",
    "location= driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe8fe36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Noida on search bar \n",
    "filter_locn =driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "filter_locn.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14846387",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_button=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "location_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the company names\n",
    "names = driver.find_elements_by_xpath('//div[@class=\"info\"]//p')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5980c3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NTT DATA GLOBAL DELIVERY SERVICES PRIVATE LIMITED',\n",
       " 'HCL Technologies Limited',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'WSP CONSULTANTS INDIA PRIVATE LIMITED',\n",
       " 'Microsoft India (R and D) Pvt Ltd',\n",
       " 'Jubilant Foodworks Limited',\n",
       " 'HCL Technologies',\n",
       " 'Hanu Software Solutions Pvt Ltd',\n",
       " 'Denave India Pvt Ltd.',\n",
       " 'Tavant Technologies India Pvt. Ltd.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "company=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 job results\n",
    "for i in names[:10]:\n",
    "    company.append(i.text)\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02f66f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags having the no of days when job was posted\n",
    "days=driver.find_elements_by_xpath('//span[1][@class=\"body-small-l\"]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b746dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6d ago',\n",
       " '7d ago',\n",
       " '17d ago',\n",
       " '8d ago',\n",
       " '18d ago',\n",
       " '5d ago',\n",
       " '22d ago',\n",
       " '7d ago',\n",
       " '1mon ago',\n",
       " '1mon ago']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "no_of_days=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 job results \n",
    "for i in days[:10]:\n",
    "    no_of_days.append(i.text)\n",
    "no_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the tags for rating of the companies\n",
    "job_rating = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "job_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "23d75776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9', '3.8', '4.1', '4.2', '4.2', '3.9', '3.8', '3.7', '4.0', '4.0']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "rating = []\n",
    "for i in job_rating:\n",
    "    rating.append(i.text)\n",
    "rating    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6e08416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\",len(company) ,len(no_of_days), len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "afb494fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job posted Days</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTT DATA GLOBAL DELIVERY SERVICES PRIVATE LIMITED</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL Technologies Limited</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSP CONSULTANTS INDIA PRIVATE LIMITED</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft India (R and D) Pvt Ltd</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hanu Software Solutions Pvt Ltd</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denave India Pvt Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tavant Technologies India Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company Name Job posted Days Rating\n",
       "0  NTT DATA GLOBAL DELIVERY SERVICES PRIVATE LIMITED          6d ago    3.9\n",
       "1                           HCL Technologies Limited          7d ago    3.8\n",
       "2     Optum Global Solutions (India) Private Limited         17d ago    4.1\n",
       "3              WSP CONSULTANTS INDIA PRIVATE LIMITED          8d ago    4.2\n",
       "4                  Microsoft India (R and D) Pvt Ltd         18d ago    4.2\n",
       "5                         Jubilant Foodworks Limited          5d ago    3.9\n",
       "6                                   HCL Technologies         22d ago    3.8\n",
       "7                    Hanu Software Solutions Pvt Ltd          7d ago    3.7\n",
       "8                              Denave India Pvt Ltd.        1mon ago    4.0\n",
       "9                Tavant Technologies India Pvt. Ltd.        1mon ago    4.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame \n",
    "df = pd.DataFrame()\n",
    "df['Company Name']=company[:10]\n",
    "df['Job posted Days']=no_of_days[:10]\n",
    "df['Rating']=rating[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aaa1a7",
   "metadata": {},
   "source": [
    "# QUESTION:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f36b1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the ambitionbox url on the web driver\n",
    "url='https://www.ambitionbox.com'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f8f3ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to click salary box  \n",
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6541d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input as Data scientist\n",
    "search_job=driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "196d7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to click on the search button\n",
    "search_btn1 = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags having the company name\n",
    "comp_name=driver.find_elements_by_xpath('//div[@class=\"company-info\"]//a')\n",
    "comp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d7432491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ab Inbev',\n",
       " 'ZS',\n",
       " 'Optum',\n",
       " 'Fractal Analytics',\n",
       " 'Tiger Analytics',\n",
       " 'UnitedHealth',\n",
       " 'Verizon',\n",
       " 'Ganit Business Solutions',\n",
       " 'Ericsson',\n",
       " 'Deloitte']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "company=[]  #Empty list\n",
    "\n",
    "#Sraping data for the first 10 job results\n",
    "for i in comp_name[:10]:\n",
    "    company.append(i.text)\n",
    "company    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3288ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags having the total salaries record\n",
    "no_salaries=driver.find_elements_by_xpath('//div[@class=\"name\"]//span')\n",
    "no_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3131636b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['based on 28 salaries',\n",
       " 'based on 15 salaries',\n",
       " 'based on 25 salaries',\n",
       " 'based on 77 salaries',\n",
       " 'based on 33 salaries',\n",
       " 'based on 52 salaries',\n",
       " 'based on 14 salaries',\n",
       " 'based on 13 salaries',\n",
       " 'based on 43 salaries',\n",
       " 'based on 57 salaries']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "no_of_salaries=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 job results\n",
    "for i in no_salaries[:10]:\n",
    "    no_of_salaries.append(i.text)\n",
    "no_of_salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2bbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags for average salary\n",
    "avg_sal=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "36a39cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 20.3L',\n",
       " '₹ 15.3L',\n",
       " '₹ 15.1L',\n",
       " '₹ 15.1L',\n",
       " '₹ 14.4L',\n",
       " '₹ 13.9L',\n",
       " '₹ 12.7L',\n",
       " '₹ 12.4L',\n",
       " '₹ 11.9L',\n",
       " '₹ 11.7L']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "avg_salary=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 job results\n",
    "for i in avg_sal[:10]:\n",
    "    avg_salary.append(i.text.replace('\\n',''))\n",
    "avg_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeea57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags for minimum salary\n",
    "min_sal=driver.find_elements_by_xpath(\"//div[1][@class='value body-medium']\")\n",
    "min_sal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c06ac6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 15.0L',\n",
       " '₹ 9.5L',\n",
       " '₹ 11.0L',\n",
       " '₹ 9.5L',\n",
       " '₹ 8.3L',\n",
       " '₹ 8.3L',\n",
       " '₹ 10.0L',\n",
       " '₹ 8.5L',\n",
       " '₹ 5.8L',\n",
       " '₹ 6.9L']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "min_salary=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 min_salary results\n",
    "for i in min_sal[:10]:\n",
    "    min_salary.append(i.text)\n",
    "min_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d79c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags for minimum salary\n",
    "max_sal=driver.find_elements_by_xpath(\"//div[2][@class='value body-medium']\")\n",
    "max_sal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8bdcb0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 25.5L',\n",
       " '₹ 20.0L',\n",
       " '₹ 21.3L',\n",
       " '₹ 22.0L',\n",
       " '₹ 20.0L',\n",
       " '₹ 20.5L',\n",
       " '₹ 21.0L',\n",
       " '₹ 15.0L',\n",
       " '₹ 24.0L',\n",
       " '₹ 23.4L']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "max_salary=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 max_salary results\n",
    "for i in max_sal[:10]:\n",
    "    max_salary.append(i.text)\n",
    "max_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aab390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tags for experience\n",
    "exp=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "exp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e72d34d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-4 yrs exp',\n",
       " '2 yrs exp',\n",
       " '3-4 yrs exp',\n",
       " '2-4 yrs exp',\n",
       " '3-4 yrs exp',\n",
       " '2-4 yrs exp',\n",
       " '4 yrs exp',\n",
       " '4 yrs exp',\n",
       " '3-4 yrs exp',\n",
       " '2-4 yrs exp']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the text from the tags\n",
    "experience=[]  #Empty list\n",
    "\n",
    "#Scraping data for the first 10 max_salary results\n",
    "for i in exp[:10]:\n",
    "    experience.append(i.text.split('\\n')[2])\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0bdb93c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\",len(company) ,len(no_of_salaries),len(avg_salary), len(min_salary),len(max_salary),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "51b87f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salary Records</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 28 salaries</td>\n",
       "      <td>₹ 20.3L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 15.3L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 25 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 77 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>₹ 14.4L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 52 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 43 salaries</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>based on 57 salaries</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "      <td>₹ 6.9L</td>\n",
       "      <td>₹ 23.4L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Number of Salary Records Average Salary  \\\n",
       "0                  Ab Inbev     based on 28 salaries        ₹ 20.3L   \n",
       "1                        ZS     based on 15 salaries        ₹ 15.3L   \n",
       "2                     Optum     based on 25 salaries        ₹ 15.1L   \n",
       "3         Fractal Analytics     based on 77 salaries        ₹ 15.1L   \n",
       "4           Tiger Analytics     based on 33 salaries        ₹ 14.4L   \n",
       "5              UnitedHealth     based on 52 salaries        ₹ 13.9L   \n",
       "6                   Verizon     based on 14 salaries        ₹ 12.7L   \n",
       "7  Ganit Business Solutions     based on 13 salaries        ₹ 12.4L   \n",
       "8                  Ericsson     based on 43 salaries        ₹ 11.9L   \n",
       "9                  Deloitte     based on 57 salaries        ₹ 11.7L   \n",
       "\n",
       "  Minimum Salary Maximum Salary   Experience  \n",
       "0        ₹ 15.0L        ₹ 25.5L  3-4 yrs exp  \n",
       "1         ₹ 9.5L        ₹ 20.0L    2 yrs exp  \n",
       "2        ₹ 11.0L        ₹ 21.3L  3-4 yrs exp  \n",
       "3         ₹ 9.5L        ₹ 22.0L  2-4 yrs exp  \n",
       "4         ₹ 8.3L        ₹ 20.0L  3-4 yrs exp  \n",
       "5         ₹ 8.3L        ₹ 20.5L  2-4 yrs exp  \n",
       "6        ₹ 10.0L        ₹ 21.0L    4 yrs exp  \n",
       "7         ₹ 8.5L        ₹ 15.0L    4 yrs exp  \n",
       "8         ₹ 5.8L        ₹ 24.0L  3-4 yrs exp  \n",
       "9         ₹ 6.9L        ₹ 23.4L  2-4 yrs exp  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the data frame \n",
    "df = pd.DataFrame()\n",
    "df['Company Name']=company\n",
    "df['Number of Salary Records']=no_of_salaries\n",
    "df['Average Salary']=avg_salary\n",
    "df['Minimum Salary']=min_salary\n",
    "df['Maximum Salary']=max_salary\n",
    "df['Experience']=experience\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd559c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
